{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "neg_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "test_pos = pos_tweets[4000:]\n",
    "train_pos = pos_tweets[:4000]\n",
    "test_neg = neg_tweets[4000:]\n",
    "train_neg = neg_tweets[:4000]\n",
    "\n",
    "x_train = train_pos + train_neg\n",
    "x_test = test_pos + test_neg\n",
    "\n",
    "y_train = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)))\n",
    "y_test = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(tweet):\n",
    "    \n",
    "    # copy over the tweet input\n",
    "    new_tweet = tweet\n",
    "    # remove links and URLS\n",
    "    new_tweet = re.sub(r'[(http(s)?):\\/\\/(www\\.)?a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)', '', tweet)\n",
    "    # remove hashtags\n",
    "    new_tweet = re.sub(r'#', '', new_tweet)\n",
    "    # remove old style retweets\n",
    "    new_tweet = re.sub(r'^RT[\\s]+', '', new_tweet)\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    eng_stopwords = stopwords.words('english')\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    \n",
    "    tweet_tokens = tokenizer.tokenize(new_tweet)\n",
    "    \n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if word in eng_stopwords:\n",
    "            continue\n",
    "        stem = stemmer.stem(word)\n",
    "        stem = stem.lower()\n",
    "        \n",
    "        tweets_clean.append(stem)\n",
    "    \n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freqs(features, labels):\n",
    "    \n",
    "    freq = {}\n",
    "    \n",
    "    for (x, y) in zip(features, labels):\n",
    "        x = preprocess_tweet(x)\n",
    "        for word in x:\n",
    "            pair = (word, y)\n",
    "\n",
    "            if pair not in freq:\n",
    "                freq[pair] = 1\n",
    "            else:\n",
    "                freq[pair] += 1\n",
    "\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7310585786300049"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, alpha, num_iter):\n",
    "    \n",
    "    m = len(X)\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        \n",
    "        z = X.dot(theta)\n",
    "        h = sigmoid(z)\n",
    "        J = (-1/m) * ((y.T.dot(np.log(h))) + ((1-y).T.dot(np.log(1-h))))\n",
    "        \n",
    "        theta = theta - (alpha/m) * (X.T.dot(h-y))\n",
    "    \n",
    "    \n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is  [[0.6709497]]\n",
      "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n"
     ]
    }
   ],
   "source": [
    "# Check the function\n",
    "# Construct a synthetic test case using numpy PRNG functions\n",
    "np.random.seed(1)\n",
    "# X input is 10 x 3 with ones for the bias terms\n",
    "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
    "# Y Labels are 10 x 1\n",
    "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
    "\n",
    "# Apply gradient descent\n",
    "tmp_J, tmp_theta = gradient_descent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
    "print(f\"The cost after training is \", tmp_J)\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, freqs):\n",
    "    \n",
    "    words = preprocess_tweet(tweet)\n",
    "    \n",
    "    x = np.zeros((1, 3))\n",
    "    x[0,0] = 1 # bias\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        if (word, 1) in freqs:\n",
    "            x[0,1] += freqs[(word, 1)]\n",
    "        elif (word, 0) in freqs:\n",
    "            x[0,2] += freqs[(word, 0)]\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 3.131e+03 6.100e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Check your function\n",
    "\n",
    "# test 1\n",
    "# test on training data\n",
    "freqs = build_freqs(x_train, y_train)\n",
    "tmp1 = extract_features(x_train[0], freqs)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69314718]\n",
      "[[ 5.00000000e-10  5.00000000e-10  5.00000000e-10 ... -5.00000000e-10\n",
      "  -5.00000000e-10 -5.00000000e-10]\n",
      " [ 1.17391831e-06  1.17391831e-06  1.17391831e-06 ... -1.17391831e-06\n",
      "  -1.17391831e-06 -1.17391831e-06]\n",
      " [ 1.33062950e-06  1.33062950e-06  1.33062950e-06 ... -1.33062950e-06\n",
      "  -1.33062950e-06 -1.33062950e-06]]\n"
     ]
    }
   ],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(x_train), 3))\n",
    "for i in range(len(x_train)):\n",
    "    X[i, :]= extract_features(x_train[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = y_train\n",
    "\n",
    "# Apply gradient descent\n",
    "J, theta = gradient_descent(X, Y, np.zeros((3, 1)), 1e-9, 1)\n",
    "print(J)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
