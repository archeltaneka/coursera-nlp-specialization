{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import io\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import codecs\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Training device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36718lines [00:01, 35358.41lines/s]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip'\n",
    "test_dir, valid_dir, train_dir = extract_archive(download_from_url(url))\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, iter(io.open(train_dir, encoding='utf-8'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(raw_text_iterator):\n",
    "    \n",
    "    data = [torch.tensor([vocab[token] for token in tokenizer(item)], dtype=torch.long) for item in raw_text_iterator]\n",
    "    \n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocess_data(iter(io.open(train_dir, encoding='utf-8')))\n",
    "val_data = preprocess_data(iter(io.open(valid_dir, encoding='utf-8')))\n",
    "test_data = preprocess_data(iter(io.open(test_dir, encoding='utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_batch(data, batch_size):\n",
    "    \n",
    "    n_batch = data.size(0) // batch_size\n",
    "    data = data.narrow(0, 0, n_batch * batch_size)\n",
    "    data = data.view(batch_size, -1).t().contiguous()\n",
    "    \n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "eval_batch_size = 16\n",
    "\n",
    "train_data = split_into_batch(train_data, batch_size)\n",
    "val_data = split_into_batch(val_data, eval_batch_size)\n",
    "test_data = split_into_batch(test_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
